{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://medium.com/better-programming/twitter-scrapers-are-all-broken-what-should-we-do-62a7349bfca6\n",
    "\n",
    "from time import sleep\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver = r\"C:\\Users\\g\\Documents\\chrome_driver\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver)\n",
    "\n",
    "# create master df to append to\n",
    "#master_df = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_for(opt1, opt2):\n",
    "    time_for = random.uniform(opt1, opt2)\n",
    "    time_for_int = int(round(time_for))\n",
    "    sleep(abs(time_for_int - time_for))\n",
    "    for i in range(time_for_int, 0, -1):\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterScraper:\n",
    "    def __init__(self):\n",
    "        self.tweetsdf = pd.DataFrame(columns=['handle','datetime','text'])\n",
    "        self.logged_set = set()\n",
    "        \n",
    "    def addTweet(self,handle,datetime,text):\n",
    "        tweethash = hashlib.sha1( datetime.encode('ANSI') + text.encode('ANSI') + handle.encode('ANSI') ).hexdigest()\n",
    "        if tweethash not in self.logged_set:\n",
    "            self.tweetsdf = self.tweetsdf.append( pd.DataFrame(data=[[handle,datetime,text]], columns=['handle','datetime','text']) )\n",
    "            return(1)\n",
    "        else:\n",
    "            self.logged_set.add(tweethash)\n",
    "            return(0)\n",
    "            \n",
    "    \n",
    "    def get_tweets(self, url, scrolls, max_strikes=2):\n",
    "        driver.get(url)\n",
    "        sleep_for(4, 5)\n",
    "\n",
    "        tweet_xpath = '//div/div/article/div/div'\n",
    "\n",
    "        already_logged = set()\n",
    "        strikes = 0\n",
    "\n",
    "        for i in range(0, scrolls):\n",
    "\n",
    "            # get a list of tweets\n",
    "            post_list = driver.find_elements_by_xpath(tweet_xpath)\n",
    "\n",
    "            # prase tweet metadata\n",
    "            for post in post_list:\n",
    "                tweets_found = 0\n",
    "                try:\n",
    "                    time_xpath = './/div/div[2]/div[2]/div[1]/div/div/div[1]/a/time'\n",
    "                    text_xpath = './/div/div[2]/div[2]/div[2]/div[1]/div'\n",
    "                    handle_xpath = './/div/div[2]/div[2]/div[1]/div/div/div[1]/div[1]/a/div/div[2]/div/span'\n",
    "                    handle = post.find_element_by_xpath(handle_xpath).text\n",
    "                    datetime = post.find_element_by_xpath(time_xpath).get_attribute('datetime')\n",
    "                    text = post.find_element_by_xpath(text_xpath).text\n",
    "\n",
    "                    tweets_found += self.addTweet(handle,datetime,text)\n",
    "                    \n",
    "                except:\n",
    "                    # likely an ad\n",
    "                    pass\n",
    "\n",
    "            if tweets_found == 0:\n",
    "                if strikes > max_strikes:\n",
    "                    break\n",
    "                strikes += 1\n",
    "            else:\n",
    "                strikes = 0\n",
    "\n",
    "            # scroll down\n",
    "            driver.find_element_by_xpath('//body').send_keys(Keys.END)\n",
    "            sleep_for(2, 4)\n",
    "\n",
    "    \n",
    "    def get_search(self, query, scrolls=5):\n",
    "        query = query.replace(' ', '%20')\n",
    "        url = 'https://twitter.com/search?q={}&src=typed_query'.format(query)\n",
    "        self.get_tweets(url, scrolls, max_strikes=2)\n",
    "        \n",
    "\n",
    "    def get_user(self, handle, scrolls):\n",
    "        url = 'https://twitter.com/{}'.format(handle)\n",
    "        self.get_tweets(url, scrolls, max_strikes=2)\n",
    "        \n",
    "    def get_df(self):\n",
    "        return(self.tweetsdf)\n",
    "    \n",
    "test = TwitterScraper()\n",
    "test.get_user('BillGates',scrolls=5)\n",
    "test.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
